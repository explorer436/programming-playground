Are people that work at Google just those that did hundreds of LeetCode questions?

Let’s answer the real question first, as it’s more interesting:

Is the Google engineering recruitment process something that you can cheat by practicing algorithmic puzzle questions?
Are Google engineers any good as engineers? (maybe not, since they are only the folks who just spent a lot of time practicing algorithmic puzzle questions?)

To the first answer, the question is “somewhat”. Google engineering interviews, especially for the lower-level positions, focus quite a lot on algorithmic puzzle solving skills (together with the accompanying implementation). It’s not the only thing tested, but it’s a major one. So, sure, practicing algorithmic puzzles will help you get hired.

However, a lot of puzzle practice is neither necessary nor sufficient to get hired. It’s not sufficient, because a lot of people just don’t have the skillset to become efficient programmers (let alone solve algorithmic puzzles well). Being a programmer requires a specific type of mental discipline that allows you to follow through the formal consequences of what you wrote, to hold the program in your head and modify it, and to speak the abstract language that computers speak. And, just before anyone screams “elitist”, the same applies to multiple other mental disciplines - for instance, I just don’t have the memory and mental skills needed to become a polyglot.

It’s not necessary, because the interview process isn’t actually about solving algorithmic puzzles. Algorithmic puzzle solving is a pretty competitive sport. To be really, really good at it you need to know all sorts of weird things. Google’s bar doesn’t require to be really, really good - it’s enough to just be reasonably good at programming and abstract thinking - a level that you can definitely get to by just being a good CS student or practicing programmer (which I know, because of a lot of people I know at Google who got hired without any competitive programming in their CV). Being better than just “reasonably good” is an advantage, of course - but it’s not required, and it’s not the biggest advantage one could have. Once you’re above the “reasonably good” bar, what is much more important is your communication skills, ability to explain stuff, experience in working in a team, a grasp of distributed system design - all things that are likely tested for most positions (distributed system design isn’t tested for entry-level positions), and more important than knowing how to write a red-black tree from scratch, or how to implement the Hungarian algorithm.

And, just in case the typed question was really what was asked: Nope. At least I never did a LeetCode question in my life. And I work at Google for 10 years.

Edit: A bunch of people in the comments ask why I consider practicing on LeetCode to be “cheating”. I don’t, but I tried to intuit the questioner’s intention. And the idea here is that solving LeetCode questions (or, in general, rote-memory knowledge of algorithms like Find-Union or Dinic or the Hungarian) is not very related to your actual skills and performance as a software engineer. And the interview system should, of course, aim to uncover the best software engineers. So, by focusing on LeetCode, you cheat the system - not necessarily by doing something unethical, but by subverting the interview system and causing it to return incorrect answers.

And, as I tried to explain in the answer, this is somewhat true - it is possible that a person who is, by most reasonable criteria, a better software engineer will be judged worse on the interview process than a person who spent a lot of time practicing on LeetCode. Which means that LeetCode is a way to cheat (in the meaning of “deceive”, “mislead”) the interviewing system. Only somewhat, but still.
