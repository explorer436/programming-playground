1. Adding retry to V1 to try to handle the errors better.
1. What happens if we do retry on the Receiver itself?
   1. The consumer will disconnect from the Partition and reconnect to it again.
   1. This is a totally unwanted behavior.
1. Separate the Reactor receiver and the processing parts.
   1. We are not doing the retry on the Receiver.
   1. Instead, we are doing retry on ~receiverRecord~
1. What is ~onRetryExhaustedThrow()~?
   1. It indicates that it should throw the original error instead of throwing ~retry count exhausted~ error.

Notice that some of them are being re-tried. ~17:07:12.241 [parallel-7] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 63 out of bounds for length 9~
However, the value of the order numbers will be increasing: ~value = order-789~ because we are acknowledging even though there are errors.

#+begin_src
 /home/explorer436/Documents/jdk-18/bin/java -javaagent:/usr/share/idea/lib/idea_rt.jar=37577:/usr/share/idea/bin -Dfile.encoding=UTF-8 -Dsun.stdout.encoding=UTF-8 -Dsun.stderr.encoding=UTF-8 -classpath /home/explorer436/Downloads/GitRepositories/programming-playground/java-playground/reactive-kafka-playground/target/classes:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-starter-webflux/3.3.2/spring-boot-starter-webflux-3.3.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-starter/3.3.2/spring-boot-starter-3.3.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot/3.3.2/spring-boot-3.3.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.3.2/spring-boot-autoconfigure-3.3.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.3.2/spring-boot-starter-logging-3.3.2.jar:/home/explorer436/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.23.1/log4j-to-slf4j-2.23.1.jar:/home/explorer436/.m2/repository/org/apache/logging/log4j/log4j-api/2.23.1/log4j-api-2.23.1.jar:/home/explorer436/.m2/repository/org/slf4j/jul-to-slf4j/2.0.13/jul-to-slf4j-2.0.13.jar:/home/explorer436/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/explorer436/.m2/repository/org/yaml/snakeyaml/2.2/snakeyaml-2.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.3.2/spring-boot-starter-json-3.3.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.17.2/jackson-databind-2.17.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.17.2/jackson-annotations-2.17.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.17.2/jackson-core-2.17.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.17.2/jackson-datatype-jdk8-2.17.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.17.2/jackson-datatype-jsr310-2.17.2.jar:/home/explorer436/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.17.2/jackson-module-parameter-names-2.17.2.jar:/home/explorer436/.m2/repository/org/springframework/boot/spring-boot-starter-reactor-netty/3.3.2/spring-boot-starter-reactor-netty-3.3.2.jar:/home/explorer436/.m2/repository/io/projectreactor/netty/reactor-netty-http/1.1.21/reactor-netty-http-1.1.21.jar:/home/explorer436/.m2/repository/io/netty/netty-codec-http/4.1.111.Final/netty-codec-http-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-codec-http2/4.1.111.Final/netty-codec-http2-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-resolver-dns/4.1.111.Final/netty-resolver-dns-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-codec-dns/4.1.111.Final/netty-codec-dns-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.111.Final/netty-resolver-dns-native-macos-4.1.111.Final-osx-x86_64.jar:/home/explorer436/.m2/repository/io/netty/netty-resolver-dns-classes-macos/4.1.111.Final/netty-resolver-dns-classes-macos-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-transport-native-epoll/4.1.111.Final/netty-transport-native-epoll-4.1.111.Final-linux-x86_64.jar:/home/explorer436/.m2/repository/io/projectreactor/netty/reactor-netty-core/1.1.21/reactor-netty-core-1.1.21.jar:/home/explorer436/.m2/repository/io/netty/netty-handler-proxy/4.1.111.Final/netty-handler-proxy-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-codec-socks/4.1.111.Final/netty-codec-socks-4.1.111.Final.jar:/home/explorer436/.m2/repository/org/springframework/spring-web/6.1.11/spring-web-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-beans/6.1.11/spring-beans-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-webflux/6.1.11/spring-webflux-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/kafka/spring-kafka/3.2.2/spring-kafka-3.2.2.jar:/home/explorer436/.m2/repository/org/springframework/spring-context/6.1.11/spring-context-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-aop/6.1.11/spring-aop-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-expression/6.1.11/spring-expression-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-messaging/6.1.11/spring-messaging-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-tx/6.1.11/spring-tx-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/retry/spring-retry/2.0.7/spring-retry-2.0.7.jar:/home/explorer436/.m2/repository/org/apache/kafka/kafka-clients/3.7.1/kafka-clients-3.7.1.jar:/home/explorer436/.m2/repository/com/github/luben/zstd-jni/1.5.6-3/zstd-jni-1.5.6-3.jar:/home/explorer436/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/home/explorer436/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/explorer436/.m2/repository/org/slf4j/slf4j-api/2.0.13/slf4j-api-2.0.13.jar:/home/explorer436/.m2/repository/io/micrometer/micrometer-observation/1.13.2/micrometer-observation-1.13.2.jar:/home/explorer436/.m2/repository/io/micrometer/micrometer-commons/1.13.2/micrometer-commons-1.13.2.jar:/home/explorer436/.m2/repository/org/projectlombok/lombok/1.18.34/lombok-1.18.34.jar:/home/explorer436/.m2/repository/org/springframework/spring-core/6.1.11/spring-core-6.1.11.jar:/home/explorer436/.m2/repository/org/springframework/spring-jcl/6.1.11/spring-jcl-6.1.11.jar:/home/explorer436/.m2/repository/io/projectreactor/reactor-core/3.6.8/reactor-core-3.6.8.jar:/home/explorer436/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar:/home/explorer436/.m2/repository/io/netty/netty-handler/4.1.111.Final/netty-handler-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-common/4.1.111.Final/netty-common-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-resolver/4.1.111.Final/netty-resolver-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-buffer/4.1.111.Final/netty-buffer-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-transport/4.1.111.Final/netty-transport-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.111.Final/netty-transport-native-unix-common-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-codec/4.1.111.Final/netty-codec-4.1.111.Final.jar:/home/explorer436/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.111.Final/netty-transport-classes-epoll-4.1.111.Final.jar:/home/explorer436/.m2/repository/ch/qos/logback/logback-core/1.5.6/logback-core-1.5.6.jar:/home/explorer436/.m2/repository/ch/qos/logback/logback-classic/1.5.6/logback-classic-1.5.6.jar:/home/explorer436/.m2/repository/io/projectreactor/kafka/reactor-kafka/1.3.17/reactor-kafka-1.3.17.jar kafka.examples.reactive.kafka.playground.error_handling.MyKafkaConsumerV2
17:07:02.465 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:8081]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-demo-group-1
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = demo-group
	group.instance.id = 1
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:07:02.513 [main] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
17:07:02.717 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
17:07:02.718 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
17:07:02.718 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1723324022715
17:07:02.741 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Subscribed to topic(s): first_kafka_topic
17:07:02.754 [main] INFO  reactor.Flux.UsingWhen.1 - onSubscribe(FluxUsingWhen.UsingWhenSubscriber)
17:07:02.755 [main] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:03.084 [reactive-kafka-demo-group-1] INFO  org.apache.kafka.clients.Metadata - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Cluster ID: OTMwNzFhYTY1ODNiNGE5OQ
17:07:03.085 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Discovered group coordinator localhost:8081 (id: 2147483646 rack: null)
17:07:03.087 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] (Re-)joining group
17:07:06.106 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Successfully joined group with generation Generation{generationId=11, memberId='1-d4a7ea6a-a51e-40e5-a0b6-d5ccf3875c35', protocol='range'}
17:07:06.135 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Finished assignment for group at generation 11: {1-d4a7ea6a-a51e-40e5-a0b6-d5ccf3875c35=Assignment(partitions=[first_kafka_topic-0])}
17:07:06.144 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Successfully synced group in generation Generation{generationId=11, memberId='1-d4a7ea6a-a51e-40e5-a0b6-d5ccf3875c35', protocol='range'}
17:07:06.145 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Notifying assignor about the new Assignment(partitions=[first_kafka_topic-0])
17:07:06.148 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer instanceId=1, clientId=consumer-demo-group-1, groupId=demo-group] Adding newly assigned partitions: first_kafka_topic-0
17:07:06.161 [reactive-kafka-demo-group-1] INFO  o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition first_kafka_topic-0 to the committed offset FetchPosition{offset=1312, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:8081 (id: 1 rack: null)], epoch=7}}
17:07:06.217 [reactive-kafka-demo-group-1] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1312, CreateTime = 1723231104837, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 787, value = order-787))
17:07:09.238 [parallel-4] INFO  k.e.r.k.p.e.MyKafkaConsumerV2 - key: 787, index: 3, value: e
17:07:09.239 [parallel-4] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:09.239 [parallel-4] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1313, CreateTime = 1723231104887, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 788, value = order-788))
17:07:12.241 [parallel-7] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 63 out of bounds for length 9
17:07:12.241 [parallel-7] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:12.241 [parallel-7] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1314, CreateTime = 1723231104937, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 789, value = order-789))
17:07:15.243 [parallel-2] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 88 out of bounds for length 9
17:07:15.243 [parallel-2] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:15.243 [parallel-2] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1315, CreateTime = 1723231104987, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 790, value = order-790))
17:07:18.245 [parallel-5] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 15 out of bounds for length 9
17:07:18.245 [parallel-5] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:18.245 [parallel-5] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1316, CreateTime = 1723231105037, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 791, value = order-791))
17:07:21.247 [parallel-8] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 80 out of bounds for length 9
17:07:21.247 [parallel-8] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:21.247 [parallel-8] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1317, CreateTime = 1723231105087, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 792, value = order-792))
17:07:24.248 [parallel-3] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 81 out of bounds for length 9
17:07:24.249 [parallel-3] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:24.249 [parallel-3] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1318, CreateTime = 1723231105137, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 793, value = order-793))
17:07:27.250 [parallel-6] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 68 out of bounds for length 9
17:07:27.251 [parallel-6] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:27.251 [parallel-6] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1319, CreateTime = 1723231105187, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 794, value = order-794))
17:07:30.252 [parallel-1] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 88 out of bounds for length 9
17:07:30.253 [parallel-1] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:30.253 [parallel-1] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1320, CreateTime = 1723231105237, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 795, value = order-795))
17:07:33.255 [parallel-4] ERROR k.e.r.k.p.e.MyKafkaConsumerV2 - Index 18 out of bounds for length 9
17:07:33.255 [parallel-4] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:33.255 [parallel-4] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1321, CreateTime = 1723231105287, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 796, value = order-796))
17:07:34.255 [parallel-5] INFO  k.e.r.k.p.e.MyKafkaConsumerV2 - key: 796, index: 8, value: 6
17:07:34.256 [parallel-5] INFO  reactor.Flux.UsingWhen.1 - request(1)
17:07:34.256 [parallel-5] INFO  reactor.Flux.UsingWhen.1 - onNext(ConsumerRecord(topic = first_kafka_topic, partition = 0, leaderEpoch = null, offset = 1322, CreateTime = 1723231105337, serialized key size = 3, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = 797, value = order-797))

Process finished with exit code 130 (interrupted by signal 2:SIGINT)
#+end_src
